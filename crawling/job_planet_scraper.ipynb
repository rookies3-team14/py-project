{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install selenium webdriver-manager beautifulsoup4 requests"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from selenium import webdriver\n",
    "from selenium.webdriver.chrome.service import Service\n",
    "from webdriver_manager.chrome import ChromeDriverManager\n",
    "from bs4 import BeautifulSoup\n",
    "import json\n",
    "\n",
    "class JobPlanetCrawler:\n",
    "    def __init__(self, url):\n",
    "        self.url = url\n",
    "        self.driver = webdriver.Chrome(service=Service(ChromeDriverManager().install()))\n",
    "        self.driver.implicitly_wait(3)\n",
    "\n",
    "    def get_html(self):\n",
    "        # HTML 소스 가져오기\n",
    "        self.driver.get(self.url)\n",
    "        return self.driver.page_source\n",
    "\n",
    "    def parse_json(self, html):\n",
    "        # HTML에서 JSON 데이터를 파싱하여 반환\n",
    "        soup = BeautifulSoup(html, \"html.parser\")\n",
    "        json_text = soup.find(\"pre\").text if soup.find(\"pre\") else \"\"\n",
    "        if json_text:\n",
    "            return json.loads(json_text)\n",
    "        else:\n",
    "            print(\"❌ <pre> 태그를 찾을 수 없습니다.\")\n",
    "            return None\n",
    "\n",
    "    def extract_job_data(self, data):\n",
    "        # JSON 데이터에서 id,경력 값 추출\n",
    "        jobs = [\n",
    "            {\n",
    "                \"id\": job.get(\"id\"),\n",
    "                \"annual_text\": job.get(\"annual\", {}).get(\"text\")\n",
    "            }\n",
    "            for job in data.get(\"data\", {}).get(\"recruits\", [])\n",
    "        ]\n",
    "        return jobs\n",
    "\n",
    "    def crawl_jobs(self):\n",
    "        # 크롤링 실행 후 결과를 반환\n",
    "        html = self.get_html()\n",
    "        data = self.parse_json(html)\n",
    "        if data:\n",
    "            jobs = self.extract_job_data(data)\n",
    "            return jobs\n",
    "        return []\n",
    "\n",
    "    def quit(self):\n",
    "        self.driver.quit()\n",
    "\n",
    "# 사용 예시\n",
    "if __name__ == \"__main__\":\n",
    "    url = \"https://www.jobplanet.co.kr/api/v3/job/postings?occupation_level1=&occupation_level2=11905,11907,11904,11906,11610,11911,11609&years_of_experience=&review_score=&job_type=&city=&education_level_id=&order_by=aggressive&page=2&page_size=8\"\n",
    "    crawler = JobPlanetCrawler(url)\n",
    "    \n",
    "    job_data = crawler.crawl_jobs()\n",
    "    \n",
    "    if job_data:\n",
    "        print(json.dumps(job_data, ensure_ascii=False, indent=2))\n",
    "    \n",
    "    crawler.quit()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
